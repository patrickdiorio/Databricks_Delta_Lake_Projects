{"cells":[{"cell_type":"markdown","source":["## Criação das tabelas TB_AUTOR,TB_LIVRO e a associativa TB_LIVRO_AUTOR"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ca00774-7e86-4baf-b408-a9e1279899c4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval Tscrisql = \"CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING,DATA_NASCIMENTO STRING) USING DELTA ;\"\nspark.sql(Tscrisql);\nval Tscrisql1 = \"CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\"\nspark.sql(Tscrisql1);\nval Tscrisql3 = \"CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE,ID_AUTOR DOUBLE) USING DELTA;\"\nspark.sql(Tscrisql3);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e7eb61c-f247-4df8-bc5d-9593dbf1b8f8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"res0","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Tscrisql: String = CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING,DATA_NASCIMENTO STRING) USING DELTA ;\nTscrisql1: String = CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\nTscrisql3: String = CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE,ID_AUTOR DOUBLE) USING DELTA;\nres0: org.apache.spark.sql.DataFrame = []\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tscrisql: String = CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING,DATA_NASCIMENTO STRING) USING DELTA ;\nTscrisql1: String = CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\nTscrisql3: String = CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE,ID_AUTOR DOUBLE) USING DELTA;\nres0: org.apache.spark.sql.DataFrame = []\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Inserção de registros na tabela TB_AUTOR"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69f1f268-4f52-41d1-995a-453b1779937d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval scrisql = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (1,'Joao','M', '01/01/1970');\"\nspark.sql(scrisql);\nval scrisql1 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (2,'Maria','F', '25/11/1975');\"\nspark.sql(scrisql1);\nval scrisql2 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (3,'Sandra','F', '14/11/1978');\"\nspark.sql(scrisql2);\nval scrisql3 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (4,'Tereza','F', '21/11/1978');\"\nspark.sql(scrisql3);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"93c58b96-0f28-4d48-b5c4-9611378025fb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"res2","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"num_affected_rows","type":"long","nullable":true,"metadata":{}},{"name":"num_inserted_rows","type":"long","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">scrisql: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (1,'Joao','M', '01/01/1970');\nscrisql1: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (2,'Maria','F', '25/11/1975');\nscrisql2: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (3,'Sandra','F', '14/11/1978');\nscrisql3: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (4,'Tereza','F', '21/11/1978');\nres2: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">scrisql: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (1,'Joao','M', '01/01/1970');\nscrisql1: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (2,'Maria','F', '25/11/1975');\nscrisql2: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (3,'Sandra','F', '14/11/1978');\nscrisql3: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (4,'Tereza','F', '21/11/1978');\nres2: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Inserção de registros na tabela TB_LIVRO"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ca5237f-548a-4288-83e7-e24d8fea4489","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval Lscrisql = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (1,'1234567890','Banco de Dados',2,10,407);\"\nspark.sql(Lscrisql);\nval Lscrisql1 = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (2,'2345678901','Redes de Computadores',1,10,60);\"\nspark.sql(Lscrisql1);\nval Lscrisql2 = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (3,'3456789012','Interface Homem-Maquina',3,10,10);\"\nspark.sql(Lscrisql2);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72a60a4f-6a69-4c10-997a-c2803b79899b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"res4","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"num_affected_rows","type":"long","nullable":true,"metadata":{}},{"name":"num_inserted_rows","type":"long","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Lscrisql: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (1,'1234567890','Banco de Dados',2,10,407);\nLscrisql1: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (2,'2345678901','Redes de Computadores',1,10,60);\nLscrisql2: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (3,'3456789012','Interface Homem-Maquina',3,10,10);\nres4: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Lscrisql: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (1,'1234567890','Banco de Dados',2,10,407);\nLscrisql1: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (2,'2345678901','Redes de Computadores',1,10,60);\nLscrisql2: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE) values (3,'3456789012','Interface Homem-Maquina',3,10,10);\nres4: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Inserção de registros na tabela TB_LIVRO_AUTOR"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"abd032f2-8485-418e-9a7b-88ccd8dd0378","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval LAscrisql = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\"\nspark.sql(LAscrisql);\nval LAscrisql1 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\"\nspark.sql(LAscrisql1);\nval LAscrisql2 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\"\nspark.sql(LAscrisql2);\nval LAscrisql3 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\"\nspark.sql(LAscrisql3);\nval LAscrisql4 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\"\nspark.sql(LAscrisql4);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1df631ee-a110-4abd-b1a9-d0314d2f1cf6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"res6","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"num_affected_rows","type":"long","nullable":true,"metadata":{}},{"name":"num_inserted_rows","type":"long","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">LAscrisql: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\nLAscrisql1: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\nLAscrisql2: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\nLAscrisql3: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\nLAscrisql4: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\nres6: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">LAscrisql: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\nLAscrisql1: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\nLAscrisql2: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\nLAscrisql3: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\nLAscrisql4: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\nres6: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Selecionando os registros, ligando todas as tabelas"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da29448a-6162-45e7-905f-401d1e36cdae","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nSELECT TB_LIVRO.TITULO, TB_LIVRO.ISBN,TB_LIVRO.PRECO,TB_AUTOR.NOME,TB_AUTOR.DATA_NASCIMENTO FROM TB_LIVRO\nINNER JOIN TB_LIVRO_AUTOR ON TB_LIVRO.ID_LIVRO = TB_LIVRO_AUTOR.ID_LIVRO\nINNER JOIN TB_AUTOR ON TB_AUTOR.ID_AUTOR = TB_LIVRO_AUTOR.ID_AUTOR"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"implicitDf":true},"nuid":"39b05110-0746-4a0b-8d31-686a8d9086a3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Interface Homem-Maquina","3456789012",10.0,"Sandra","14/11/1978"],["Interface Homem-Maquina","3456789012",10.0,"Maria","25/11/1975"],["Redes de Computadores","2345678901",10.0,"Sandra","14/11/1978"],["Banco de Dados","1234567890",10.0,"Maria","25/11/1975"],["Banco de Dados","1234567890",10.0,"Joao","01/01/1970"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"TITULO","type":"\"string\"","metadata":"{}"},{"name":"ISBN","type":"\"string\"","metadata":"{}"},{"name":"PRECO","type":"\"double\"","metadata":"{}"},{"name":"NOME","type":"\"string\"","metadata":"{}"},{"name":"DATA_NASCIMENTO","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>TITULO</th><th>ISBN</th><th>PRECO</th><th>NOME</th><th>DATA_NASCIMENTO</th></tr></thead><tbody><tr><td>Interface Homem-Maquina</td><td>3456789012</td><td>10.0</td><td>Sandra</td><td>14/11/1978</td></tr><tr><td>Interface Homem-Maquina</td><td>3456789012</td><td>10.0</td><td>Maria</td><td>25/11/1975</td></tr><tr><td>Redes de Computadores</td><td>2345678901</td><td>10.0</td><td>Sandra</td><td>14/11/1978</td></tr><tr><td>Banco de Dados</td><td>1234567890</td><td>10.0</td><td>Maria</td><td>25/11/1975</td></tr><tr><td>Banco de Dados</td><td>1234567890</td><td>10.0</td><td>Joao</td><td>01/01/1970</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Criando uma check constraints para a tabela TB_AUTOR, somente permitindo a inserção de 4 registros"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"845ae171-ce7b-4853-b388-4f940f3693cd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nALTER TABLE TB_AUTOR DROP CONSTRAINT validIds;\nALTER TABLE TB_AUTOR ADD CONSTRAINT validIds CHECK (ID_AUTOR> 0 and ID_AUTOR < 5);\nSHOW TBLPROPERTIES TB_AUTOR;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"implicitDf":true},"nuid":"7068140a-c7a2-4e30-a474-ee2d447de674","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Type","MANAGED"],["delta.constraints.validids","ID_AUTOR > 0 and ID_AUTOR < 5"],["delta.minReaderVersion","1"],["delta.minWriterVersion","3"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"key","type":"\"string\"","metadata":"{}"},{"name":"value","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>Type</td><td>MANAGED</td></tr><tr><td>delta.constraints.validids</td><td>ID_AUTOR > 0 and ID_AUTOR < 5</td></tr><tr><td>delta.minReaderVersion</td><td>1</td></tr><tr><td>delta.minWriterVersion</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Verificando se a check constraints irá funcionar, executando um insert"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"adecbea6-b5e8-449f-bfd4-b17c51e89bb9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval scrisql = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (5,'Joao','M', '01/01/1970');\"\nspark.sql(scrisql);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8f419caf-8da6-4743-b746-65329580e795","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"> - ID_AUTOR : 5.0\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:59)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:69)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:90)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:437)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1715)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:444)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:336)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:156)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:125)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:95)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:832)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1681)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:835)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:690)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)</div>","errorSummary":"InvariantViolationException: CHECK constraint validids ((ID_AUTOR > 0) AND (ID_AUTOR < 5)) violated by row with values:\n - ID_AUTOR : 5.0","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"> - ID_AUTOR : 5.0\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:59)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:69)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:90)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:437)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1715)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:444)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:336)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:156)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:125)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:95)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:832)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1681)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:835)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:690)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Projeto_Livraria_Delta_Lake","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1102759827964467,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":1102759827964455}},"nbformat":4,"nbformat_minor":0}
